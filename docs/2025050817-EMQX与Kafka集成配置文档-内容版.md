# EMQX与Kafka集成配置文档

本文档详细描述了在Win10 Docker Desktop环境下，如何配置EMQX开源版集群和Kafka集群以支持IOT模块需求的步骤。

## 1. 配置概览

基于需求，我们需要完成以下配置：

1. EMQX集群配置：
   - 设备认证机制
   - MQTT Topic设计实现
   - Kafka桥接配置

2. Kafka集群配置：
   - 创建所需Topic
   - 配置Topic分区
   - 消费者组设置

## 2. EMQX集群配置

### 2.1 基础调整

在开始进一步配置前，需确保EMQX集群已按`中间件部署代码.md`正确部署并运行。

通过浏览器访问`http://localhost:18083`（用户名：admin，密码：public）以验证EMQX集群状态。

### 2.2 设备认证配置

#### 2.2.1 启用HTTP认证

1. 创建HTTP认证服务（在项目中实现）

创建一个简单的SpringBoot服务，实现认证逻辑：

```java
@RestController
@RequestMapping("/mqtt")
public class MqttAuthController {

    @PostMapping("/auth")
    public Map<String, Object> authenticate(
            @RequestParam("username") String username,
            @RequestParam("password") String password) {
        
        // 检查设备ID是否有效
        if (!isValidDeviceId(username)) {
            return Map.of("result", "deny");
        }
        
        // 验证密码 - 当前小时和前一小时的密钥都有效
        SimpleDateFormat sdf = new SimpleDateFormat("yyyyMMddHH");
        String currentHour = sdf.format(new Date());
        
        // 计算前一小时
        Calendar cal = Calendar.getInstance();
        cal.add(Calendar.HOUR_OF_DAY, -1);
        String previousHour = sdf.format(cal.getTime());
        
        // 计算两个可能的有效密钥
        String currentKey = DigestUtils.md5Hex(username + currentHour).toLowerCase();
        String previousKey = DigestUtils.md5Hex(username + previousHour).toLowerCase();
        
        // 验证密码
        if (password.equals(currentKey) || password.equals(previousKey)) {
            return Map.of("result", "allow");
        }
        
        return Map.of("result", "deny");
    }
    
    private boolean isValidDeviceId(String deviceId) {
        // 实现设备ID有效性检查
        // 例如：检查格式是否正确，设备是否在数据库中注册
        return deviceId.matches("^[0-9A-F]{8}$");
    }
}
```

2. 在EMQX Dashboard中配置HTTP认证：

   a. 进入Dashboard后，转到"Access Control" > "Authentication"
   
   b. 点击"Create" > 选择"Password-Based" > "HTTP Server"
   
   c. 配置HTTP认证服务器：
      - Backend URL: http://{host-ip}:8080/mqtt/auth
      - Method: POST
      - Content Type: application/json
      - Headers: 保持默认
   
   d. 保存配置

3. 通过Docker CLI配置EMQX：

```bash
# 进入EMQX节点1容器
docker exec -it emqx-node1 bash

# 修改emqx.conf添加HTTP认证配置
echo '
## 认证
authentication = [
  {
    enable = true,
    mechanism = "password_based",
    backend = "http",
    method = "post",
    url = "http://host.docker.internal:8080/mqtt/auth",
    headers.content_type = "application/json",
    body.username = "${username}",
    body.password = "${password}",
    pool_size = 8,
    connect_timeout = "5s",
    request_timeout = "5s",
    enable_pipelining = 100,
    ssl.enable = false
  }
]' >> /opt/emqx/etc/emqx.conf

# 重新加载配置
emqx ctl conf reload
```

对集群中其他节点重复以上操作。

### 2.3 MQTT Topic设计实现

按照需求的Topic设计，我们需要在EMQX中创建适当的Topic权限控制规则。

1. 创建访问控制规则 (ACL)：

```bash
docker exec -it emqx-node1 bash

# 设置ACL规则
cat << EOF > /opt/emqx/etc/acl.conf
{allow, {username, {re, "^[0-9A-F]{8}$"}}, 
   subscribe, [
     "/{env}/{tenantId}/{deviceModel}/{branch}/${username}/base/#",
     "/{env}/{tenantId}/{deviceModel}/broadcast"
   ]}.

{allow, {username, {re, "^[0-9A-F]{8}$"}},
   publish, [
     "/{env}/{tenantId}/{deviceModel}/{branch}/${username}/base/status",
     "/{env}/{tenantId}/{deviceModel}/{branch}/${username}/base/event",
     "/{env}/{tenantId}/{deviceModel}/{branch}/${username}/base/command/response"
   ]}.

{allow, all, subscribe, ["$SYS/#"]}.
{allow, all, publish, ["$SYS/#"]}.

{deny, all, subscribe, ["/#"]}.
{deny, all, publish, ["/#"]}.
EOF

# 加载ACL配置
emqx ctl acl reload
```

### 2.4 EMQX-Kafka桥接配置

使用EMQX Kafka桥接插件将消息转发到Kafka：

1. 安装EMQX Kafka插件：

```bash
docker exec -it emqx-node1 bash

# 安装插件
emqx ctl plugins install emqx_bridge_kafka

# 启用插件
emqx ctl plugins enable emqx_bridge_kafka
```

2. 配置Kafka桥接：

创建桥接配置文件：

```bash
docker exec -it emqx-node1 bash

cat << EOF > /opt/emqx/etc/plugins/emqx_bridge_kafka.conf
## Kafka 服务器地址
bridge.kafka.servers = host.docker.internal:29092,host.docker.internal:39092

## Kafka 生产者配置
bridge.kafka.producer.bootstrap.servers = host.docker.internal:29092,host.docker.internal:39092
bridge.kafka.producer.compression.type = snappy
bridge.kafka.producer.max.request.size = 1048576
bridge.kafka.producer.acks = 1

## 服务质量等级 - 至少一次
bridge.kafka.producer.qos = 1

## 设备状态消息桥接规则
bridge.kafka.rule.status.topic = /+/+/+/+/+/base/status
bridge.kafka.rule.status.target = iot-device-status

## 设备事件消息桥接规则
bridge.kafka.rule.event.topic = /+/+/+/+/+/base/event
bridge.kafka.rule.event.target = iot-device-event

## 设备命令响应消息桥接规则
bridge.kafka.rule.cmd_resp.topic = /+/+/+/+/+/base/command/response
bridge.kafka.rule.cmd_resp.target = iot-device-command-response
EOF

# 重启插件
emqx ctl plugins disable emqx_bridge_kafka
emqx ctl plugins enable emqx_bridge_kafka
```

3. 配置规则引擎（可选）：

通过EMQX Dashboard配置规则引擎，对消息进行预处理：

a. 进入Dashboard > "Rules" > "Create"
b. SQL语句如下：
```sql
SELECT
  clientid as device_id,
  topic as mqtt_topic,
  payload,
  now_timestamp() as server_time
FROM
  "/+/+/+/+/+/base/status"
```
c. 添加动作：Republish，目标Topic为"$bridge/kafka/iot-device-status"

## 3. Kafka集群配置

### 3.1 创建所需Topic

确保Kafka集群已按`中间件部署代码.md`正确部署并运行，然后创建相关Topic：

```bash
# 进入Kafka容器
docker exec -it kafka2 bash

# 创建设备状态Topic (5个分区，复制因子为2)
kafka-topics.sh --create --topic iot-device-status --bootstrap-server kafka2:9092,kafka3:9092 --partitions 5 --replication-factor 2

# 创建设备事件Topic
kafka-topics.sh --create --topic iot-device-event --bootstrap-server kafka2:9092,kafka3:9092 --partitions 5 --replication-factor 2

# 创建设备命令Topic
kafka-topics.sh --create --topic iot-device-command --bootstrap-server kafka2:9092,kafka3:9092 --partitions 5 --replication-factor 2

# 创建设备命令响应Topic
kafka-topics.sh --create --topic iot-device-command-response --bootstrap-server kafka2:9092,kafka3:9092 --partitions 5 --replication-factor 2

# 创建消息重试队列
kafka-topics.sh --create --topic iot-message-retry --bootstrap-server kafka2:9092,kafka3:9092 --partitions 10 --replication-factor 2 --config retention.ms=86400000
```

### 3.2 配置Topic分区策略

为确保同一设备的消息有序处理，配置基于deviceId的分区策略，以下提供详细的操作步骤：

#### 3.2.1 理解分区策略的重要性

在IoT场景中，保证同一设备的消息按顺序处理至关重要，原因如下：
- 确保状态更新的时序正确性
- 避免命令执行顺序错乱
- 提高处理效率和一致性

默认情况下，Kafka采用轮询或随机分区策略，无法保证同一设备的消息进入同一分区。

#### 3.2.2 实现自定义分区器

1. 在项目中创建`kafka/partitioner`包，并添加以下`DeviceIdPartitioner`类：

```java
package com.goodsop.iot.kafka.partitioner;

import org.apache.kafka.clients.producer.Partitioner;
import org.apache.kafka.common.Cluster;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Map;
import java.util.Random;

public class DeviceIdPartitioner implements Partitioner {
    private static final Logger log = LoggerFactory.getLogger(DeviceIdPartitioner.class);
    
    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
        int partitionCount = cluster.partitionCountForTopic(topic);
        if (partitionCount <= 0) {
            throw new IllegalStateException("Topic " + topic + " doesn't exist or has no partitions");
        }
        
        if (key == null || !(key instanceof String)) {
            // 如果没有key，使用随机分区
            int randomPartition = (new Random().nextInt() & Integer.MAX_VALUE) % partitionCount;
            log.debug("No device ID key provided, using random partition: {}", randomPartition);
            return randomPartition;
        }
        
        String deviceId = (String) key;
        // 使用deviceId的哈希值确保相同deviceId的消息发送到同一分区
        int targetPartition = Math.abs(deviceId.hashCode()) % partitionCount;
        log.debug("Device ID: {}, assigned to partition: {}", deviceId, targetPartition);
        return targetPartition;
    }
    
    @Override
    public void close() {
        // 无需特殊清理
    }
    
    @Override
    public void configure(Map<String, ?> configs) {
        // 可以从配置中读取自定义参数
        log.info("DeviceIdPartitioner configured with: {}", configs);
    }
}
```

2. 确保将此类添加到构建路径中：

```xml
<!-- 在pom.xml中添加Kafka客户端依赖 -->
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>3.4.0</version> <!-- 使用与Kafka服务器兼容的版本 -->
</dependency>
```

#### 3.2.3 在生产者配置中使用自定义分区器

1. 创建Kafka生产者配置类：

```java
package com.goodsop.iot.config;

import com.goodsop.iot.kafka.partitioner.DeviceIdPartitioner;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;

import java.util.HashMap;
import java.util.Map;

@Configuration
public class KafkaProducerConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    @Bean
    public ProducerFactory<String, String> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        
        // 基础连接配置
        configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        
        // 使用自定义分区器
        configProps.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, DeviceIdPartitioner.class.getName());
        
        // 性能和可靠性配置
        configProps.put(ProducerConfig.ACKS_CONFIG, "1"); // 设置确认级别
        configProps.put(ProducerConfig.RETRIES_CONFIG, 3); // 重试次数
        configProps.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384); // 批次大小
        configProps.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432); // 缓冲区大小
        configProps.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "snappy"); // 压缩类型
        
        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}
```

2. 在应用属性文件中配置Kafka连接：

```properties
# application.properties 或 application.yml
spring.kafka.bootstrap-servers=localhost:29092,localhost:39092
```

#### 3.2.4 在消息发送时使用设备ID作为消息键

确保在发送消息时，将设备ID设置为消息的键：

```java
@Service
public class DeviceMessageService {
    private final KafkaTemplate<String, String> kafkaTemplate;
    private static final Logger log = LoggerFactory.getLogger(DeviceMessageService.class);

    public DeviceMessageService(KafkaTemplate<String, String> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    public void sendDeviceStatus(String deviceId, String statusJson) {
        // 使用deviceId作为消息键，确保相同设备的消息进入同一分区
        kafkaTemplate.send("iot-device-status", deviceId, statusJson)
            .addCallback(
                result -> log.info("Device status sent for: {}, partition: {}", 
                                  deviceId, result.getRecordMetadata().partition()),
                ex -> log.error("Failed to send status for device: {}", deviceId, ex)
            );
    }
}
```

#### 3.2.5 验证分区策略是否生效

可以通过以下步骤验证分区策略是否正常工作：

1. 启动Kafka控制台消费者，指定查看所有分区：

```bash
# 进入Kafka容器
docker exec -it kafka2 bash

# 查看消息及其所在分区
kafka-console-consumer.sh --topic iot-device-status --bootstrap-server kafka2:9092 --from-beginning --property print.partition=true
```

2. 使用测试程序发送相同设备ID的多条消息，然后观察输出，确认消息都进入了同一分区：

```bash
# 输出示例（注意分区号应相同）
Partition:0 {"deviceId":"0000FFFF","status":"online"}
Partition:0 {"deviceId":"0000FFFF","batteryLevel":85}
```

3. 使用Kafka UI监控分区分配情况：
   - 打开http://localhost:38080
   - 选择"Topics" > "iot-device-status"
   - 查看"Partitions"选项卡，观察消息分布

如果不同设备的消息被分配到不同分区，而同一设备的消息始终在同一分区，则表明分区策略配置成功。

#### 3.2.6 常见问题与解决方案

1. **分区不平衡**：如果观察到某些分区负载明显高于其他分区，可能是由于设备ID哈希分布不均匀造成的。解决方案：
   ```java
   // 改进的哈希算法，使用MurmurHash提高均匀性
   int partition = Hashing.murmur3_32().hashString(deviceId, StandardCharsets.UTF_8).asInt() % partitionCount;
   ```

2. **重启后分区变化**：如果Kafka集群重启或扩展后分区分配发生变化，解决方案：
   - 使用一致性哈希算法
   - 固定分区数量，避免动态调整

3. **部分消息没有设备ID**：对于某些系统或广播消息可能没有特定设备ID，解决方案：
   - 为系统消息使用固定的虚拟设备ID
   - 为广播消息使用专门的Topic

通过以上详细配置和验证步骤，可以确保IoT设备消息按照设备ID正确路由到固定分区，保证同一设备消息的处理顺序。

### 3.3 消费者组配置

为不同类型的消息处理设置独立的消费者组：

```java
// 状态监控消费者组
Properties statusConsumerProps = new Properties();
statusConsumerProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:29092,localhost:39092");
statusConsumerProps.put(ConsumerConfig.GROUP_ID_CONFIG, "iot-status-consumer-group");
statusConsumerProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
statusConsumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
statusConsumerProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "latest");
statusConsumerProps.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false");

// 事件处理消费者组
Properties eventConsumerProps = new Properties();
eventConsumerProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:29092,localhost:39092");
eventConsumerProps.put(ConsumerConfig.GROUP_ID_CONFIG, "iot-event-consumer-group");
// ... 其他配置与状态监控消费者组类似
```

## 4. 验证配置

### 4.1 验证EMQX配置

1. 使用MQTT客户端工具（如MQTTX）连接EMQX：
   - 主机：localhost
   - 端口：1883
   - 客户端ID：可留空（会自动使用username）
   - 用户名：0000FFFF（设备ID）
   - 密码：MD5(0000FFFF+当前小时YYYYMMDDHH)

2. 发布消息到允许的主题：
   - 主题：/dev/AAA11/832/master/0000FFFF/base/status
   - 消息：{"deviceId":"0000FFFF","firmwareVersion":"v1.2.3","batteryLevel":85}

### 4.2 验证Kafka配置

1. 查看Topic是否创建成功：

```bash
docker exec -it kafka2 kafka-topics.sh --list --bootstrap-server kafka2:9092
```

2. 查看消息是否正确转发到Kafka：

```bash
docker exec -it kafka2 kafka-console-consumer.sh --topic iot-device-status --bootstrap-server kafka2:9092 --from-beginning
```

3. 观察Kafka UI（http://localhost:38080）中的主题数据。

## 5. 故障排除

1. **EMQX与Kafka连接问题**：
   - 检查Docker网络连接
   - 确保host.docker.internal正确解析到宿主机IP
   - 检查防火墙设置

2. **认证问题**：
   - 检查认证服务日志
   - 验证MD5计算是否一致
   - 确认设备ID格式正确

3. **消息路由问题**：
   - 检查EMQX日志
   - 验证Topic格式是否匹配规则
   - 确保ACL规则正确配置

## 6. 部署建议

当前配置适用于开发环境（Win10 Docker Desktop），生产环境部署时建议：

1. 确保EMQX和Kafka集群的高可用性
2. 配置适当的资源限制
3. 启用TLS/SSL加密保护通信安全
4. 实施全面的监控和告警机制
5. 设置适当的日志轮换和保留策略 